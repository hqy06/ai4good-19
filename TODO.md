# Models

## :heavy_check_mark: K Nearest Neighbor

- [x] Note
- [x] Write code
- [x] Debug using IRIS
- [ ] More test (optional)

## :heavy_check_mark: K Means

- [x] Note
- [x] Write Code
- [x] Debug using WINE
- [ ] Implement Soft K-Means (optional)
- [ ] Debug using datasets (later)

Try use the precision matrix, i.e. $(a_{ij})$ in which each row is the result of clustering prediction and each column for the actual label.
Also, check [MNIST 2d visualization](https://colah.github.io/posts/2014-10-Visualizing-MNIST/)

Bishop: life time good book to read

Read later: [link](https://scikit-learn.org/stable/auto_examples/cluster/plot_mini_batch_kmeans.html#sphx-glr-auto-examples-cluster-plot-mini-batch-kmeans-py)

## :heavy_check_mark: MLP: fully-connected feed-forward NN

- [x] Note
- [x] Simple MLP: no debug!
- [x] MLP in `sklearn`
- [x] ~~MLP in `pytorch`~~ not necessary

## :heavy_check_mark: CNN: convolution neural net

- [x] ~~Note~~ See study note in _19W_ notebook
- [x] Simple Code
- [x] Tutorial by ~~@[Puneet Grover](https://www.kaggle.com/puneetgrover)~~ Write your own after reading so much stuffs!

## RNN: recurrent neural net

- [x] Note
- [x] vanilla RNN with PyTorch official tutorial
- [ ] word-level RNN generator with LSTM cells

---

# Talks

## Reinforce Learning

- [ ] Prof. Precup: day 2
- [ ] Prof. Precup: day 3
- [ ] TBA

## Monte Carlo Tree Search

- [ ] TBA

## Natural Language Processing

- [ ] TBA

---

# Misc

[Click me for github markdown emoji](https://gist.github.com/rxaviers/7360908)

[math in matplotlib](https://matplotlib.org/tutorials/text/mathtext.html)

[Atom Hydrogen Debug](https://nteract.gitbooks.io/hydrogen/docs/Troubleshooting.html)

[A Recipe for Training Neural Net](http://karpathy.github.io/2019/04/25/recipe/)
